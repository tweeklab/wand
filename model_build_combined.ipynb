{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import yaml\n",
    "import warnings\n",
    "import pickle\n",
    "\n",
    "from cachetools import cached\n",
    "from itertools import product\n",
    "\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "\n",
    "from tqdm.notebook import tqdm\n",
    "from sklearn.metrics import f1_score\n",
    "from PIL import Image\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "from netconfig import NetConfig\n",
    "\n",
    "np.set_printoptions(precision=4)\n",
    "warnings.filterwarnings('ignore')\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '2'\n",
    "\n",
    "import tensorflow as tf\n",
    "tf.debugging.set_log_device_placement(False)\n",
    "tf.random.set_seed(42)\n",
    "\n",
    "print(f\"Tensorflow version: {tf.__version__}\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training Configuration\n",
    "Set `SELECTED_MODEL` to `None` to perform a parameter search, or set it\n",
    "to a `NetConfig` object with the chosen configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "LABELS_PATH=\"labels.yaml\"\n",
    "IMAGES_BASE=\"/workspaces/motion/images/esp32/good\"\n",
    "DISCARD_IMAGES_DIR=\"images/esp32/discard\"\n",
    "BATCH_SIZE=10\n",
    "\n",
    "# SELECTED_MODEL=None\n",
    "SELECTED_MODEL=NetConfig(conv_layers=4, conv_per_layer=6, conv_kernel_shape=(3, 3), dropout1=0.7, dropout2=0.5, dense_size=128)\n",
    "# Current best:\n",
    "# SELECTED_MODEL=NetConfig(conv_layers=4, conv_per_layer=3, conv_kernel_shape=(3, 3), dropout1=0.7, dropout2=0.5, dense_size=128)\n",
    "# SELECTED_MODEL=NetConfig(conv_layers=4, conv_per_layer=3, conv_kernel_shape=(3, 3), dropout1=0.5, dropout2=0.7, dense_size=128)\n",
    "# SELECTED_MODEL=NetConfig(conv_layers=2, conv_per_layer=6, conv_kernel_shape=(3, 3), dropout1=0.5, dropout2=0.7, dense_size=128)\n",
    "# SELECTED_MODEL=NetConfig(conv_layers=4, conv_per_layer=2, conv_kernel_shape=(3, 3), dropout1=0.5, dropout2=0.7, dense_size=128)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load labels globally"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(LABELS_PATH) as f:\n",
    "    label_map = yaml.load(f, Loader=yaml.SafeLoader)[\"labels\"]\n",
    "reverse_label_map = {v:k for k,v in label_map.items()}"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Utility functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tf_init():\n",
    "  # Taken from tensorflow GPU docs\n",
    "  # https://www.tensorflow.org/guide/gpu\n",
    "  gpus = tf.config.list_physical_devices('GPU')\n",
    "  if gpus:\n",
    "    try:\n",
    "      # Currently, memory growth needs to be the same across GPUs\n",
    "      for gpu in gpus:\n",
    "        tf.config.experimental.set_memory_growth(gpu, True)\n",
    "        # tf.config.experimental.set_virtual_device_configuration(\n",
    "        #   gpu, [tf.config.LogicalDeviceConfiguration(memory_limit=1024)]\n",
    "        # )\n",
    "      logical_gpus = tf.config.list_logical_devices('GPU')\n",
    "      print(len(gpus), \"Physical GPUs,\", len(logical_gpus), \"Logical GPUs\")\n",
    "    except RuntimeError as e:\n",
    "      # Memory growth must be set before GPUs have been initialized\n",
    "      print(e)\n",
    "\n",
    "@cached(cache={})\n",
    "def load_train_data():\n",
    "    examples = []\n",
    "    examples_labels = []\n",
    "    for dir,_,files in os.walk(IMAGES_BASE):\n",
    "        for file in files:\n",
    "            examples.append(np.asarray(Image.open(os.path.join(dir, file)).point(lambda x: 255 if x>0 else 0), dtype=np.float32).reshape(29, 40, 1))\n",
    "            examples_labels.append(label_map[os.path.basename(dir)])\n",
    "    examples_numpy = np.asarray(examples)\n",
    "    examples_labels_numpy = np.asanyarray(examples_labels)\n",
    "\n",
    "    ds = tf.data.Dataset.from_tensor_slices((examples_numpy, examples_labels_numpy))\n",
    "    ds = ds.shuffle(buffer_size=2000, reshuffle_each_iteration=False).batch(BATCH_SIZE)\n",
    "\n",
    "    val_ds = ds.take(10)\n",
    "    test_ds = ds.skip(10).take(10)\n",
    "    train_ds = ds.skip(20)\n",
    "\n",
    "    return (train_ds, val_ds, test_ds)\n",
    "\n",
    "@cached(cache={})\n",
    "def load_discard_images():\n",
    "    discard_files = []\n",
    "    garbage_image_arrays = []\n",
    "    for dir,_,files in os.walk(DISCARD_IMAGES_DIR):\n",
    "        for file in files:\n",
    "            discard_files.append(os.path.join(dir, file))\n",
    "\n",
    "    for imgfile in discard_files:\n",
    "        i = Image.open(imgfile).point(lambda x: 255 if x>0 else 0)\n",
    "        garbage_img_array = np.asarray(i, dtype=np.float32).reshape(29,40, 1)\n",
    "        garbage_image_arrays.append(garbage_img_array)\n",
    "\n",
    "    all_garbage_images = np.array(garbage_image_arrays)\n",
    "    garbage_ds = tf.data.Dataset.from_tensor_slices(all_garbage_images)\n",
    "\n",
    "    return garbage_ds.batch(BATCH_SIZE)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model config generator for parameter searches\n",
    "The variables at the top of the generator define the parameter grid.\n",
    "See the definition of NetConfig in `netconfig.py` for all the fields.  I pulled\n",
    "the definition of that object class out to its own module because it was less problematic\n",
    "when I tried to pickle, unpickle things containing objects of that class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def config_generator():\n",
    "  conv_layers = [1,2]\n",
    "  conv_per_layer = [4,6]\n",
    "  conv_kernel_shape = [(3,3), (5,5)]\n",
    "  dropout1 = [.7, .8, .9]\n",
    "  dropout2 = [.7, .8, .9]\n",
    "  dense_size = [256, 384, 512]\n",
    "\n",
    "  grid = [\n",
    "    conv_layers,\n",
    "    conv_per_layer,\n",
    "    conv_kernel_shape,\n",
    "    dropout1,\n",
    "    dropout2,\n",
    "    dense_size\n",
    "  ]\n",
    "\n",
    "  for c in product(*grid):\n",
    "    yield NetConfig(\n",
    "      conv_layers=c[0],\n",
    "      conv_per_layer=c[1],\n",
    "      conv_kernel_shape=c[2],\n",
    "      dropout1=c[3],\n",
    "      dropout2=c[4],\n",
    "      dense_size=c[5]\n",
    "    )"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Build a network and train a model according to a passed NetConfig\n",
    "This returns the Tensorflow History object from the call to fit().  You can get\n",
    "the model in the `model` attribute of this object."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_model(config: NetConfig, train_ds, val_ds):\n",
    "  layers = []\n",
    "  for i in range(config.conv_layers):\n",
    "    layers.append(\n",
    "      tf.keras.layers.Conv2D(config.conv_per_layer, config.conv_kernel_shape, padding='same', activation='relu')\n",
    "    )\n",
    "  layers.append(tf.keras.layers.MaxPool2D(strides=(2,2)))\n",
    "  layers.append(tf.keras.layers.Flatten())\n",
    "  layers.append(tf.keras.layers.Dropout(config.dropout1))\n",
    "  layers.append(tf.keras.layers.Dense(config.dense_size, activation='relu'))\n",
    "  layers.append(tf.keras.layers.Dropout(config.dropout2))\n",
    "  layers.append(tf.keras.layers.Dense(8, activation='softmax'))\n",
    "  model = tf.keras.models.Sequential(layers)\n",
    "\n",
    "  model.compile(\n",
    "    optimizer=tf.keras.optimizers.Adam(learning_rate=.0005),\n",
    "    loss=tf.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
    "    metrics=[tf.keras.metrics.SparseCategoricalAccuracy()],\n",
    "  )\n",
    "\n",
    "  log_dir = \"logs/fit/\"\n",
    "  tensorboard_callback = tf.keras.callbacks.TensorBoard(log_dir=log_dir, histogram_freq=1)\n",
    "\n",
    "  stoping_callback = tf.keras.callbacks.EarlyStopping(\n",
    "    monitor='loss',\n",
    "    mode='min',\n",
    "    patience=10,\n",
    "    verbose=1,\n",
    "    restore_best_weights=True,\n",
    "    start_from_epoch=100\n",
    "  )\n",
    "\n",
    "  history = model.fit(\n",
    "      train_ds,\n",
    "      epochs=200,\n",
    "      validation_data=val_ds,\n",
    "      callbacks=[\n",
    "        stoping_callback,\n",
    "        tensorboard_callback\n",
    "      ],\n",
    "      verbose=0,\n",
    "  )\n",
    "  return history"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Functions for parameter search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_and_evaluate_model(c: NetConfig):\n",
    "    (train_ds, val_ds, test_ds) = load_train_data()\n",
    "    h = generate_model(c, train_ds, val_ds)\n",
    "    model = h.model\n",
    "\n",
    "    real_classes = []\n",
    "    pred_classes = []\n",
    "    count_high_prob = 0\n",
    "\n",
    "    for batch in test_ds:\n",
    "        preds = model.predict(batch[0], verbose=0)\n",
    "        tmp_max_value = np.amax(preds, axis=1)\n",
    "        count_high_prob += np.count_nonzero(tmp_max_value > .8)\n",
    "        pred_classes.extend(tf.argmax(preds, axis=1).numpy())\n",
    "        real_classes.extend(batch[1].numpy())\n",
    "\n",
    "    weighted_f1 = f1_score(real_classes, pred_classes, average='weighted')\n",
    "    micro_f1 = f1_score(real_classes, pred_classes, average='micro')\n",
    "    macro_f1 = f1_score(real_classes, pred_classes, average='macro')\n",
    "\n",
    "    discard_images = load_discard_images()\n",
    "    preds = model.predict(discard_images, verbose=0)\n",
    "    max_value = np.amax(preds, axis=1)\n",
    "    high_prob_crap_percent = (np.count_nonzero(max_value > .8)/len(max_value))*100\n",
    "    ret =  {\n",
    "        'model': model,\n",
    "        'config': c,\n",
    "        'weighted_f1': weighted_f1,\n",
    "        'micro_f1': micro_f1,\n",
    "        'macro_f1': macro_f1,\n",
    "        'high_prob_good_percent': (count_high_prob/len(pred_classes))*100,\n",
    "        'high_prob_crap_percent': high_prob_crap_percent\n",
    "    }\n",
    "    ret.update({k: v[29] for k,v in h.history.items()})\n",
    "    return ret\n",
    "\n",
    "def param_search():\n",
    "    tf_init()\n",
    "    rets = []\n",
    "    configs = [c for c in config_generator()]\n",
    "    for c in tqdm(configs[:5]):\n",
    "        r = train_and_evaluate_model(c)\n",
    "        del r['model']\n",
    "        print(r)\n",
    "        rets.append(r)\n",
    "\n",
    "    # with open(\"param_results.p\", \"wb\") as f:\n",
    "    #     pickle.dump(rets, f)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Network parameter/config search\n",
    "This will run if `SELECTED_MODEL` is set to `None` at the top of this notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not SELECTED_MODEL:\n",
    "    param_search()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Functions for evaluating a single chosen model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def confusion_matrix_for_model(model, test_ds):\n",
    "    real_classes = []\n",
    "    pred_classes = []\n",
    "\n",
    "    for batch in test_ds:\n",
    "        preds = model.predict(batch[0], verbose=0)\n",
    "        pred_classes.extend(tf.argmax(preds, axis=1).numpy())\n",
    "        real_classes.extend(batch[1].numpy())\n",
    "\n",
    "    weighted_f1 = f1_score(real_classes, pred_classes, average='weighted')\n",
    "    conf_matrix = tf.math.confusion_matrix(real_classes, pred_classes)\n",
    "\n",
    "    fig, ax = plt.subplots(figsize=(7.5, 7.5))\n",
    "    ax.matshow(conf_matrix, cmap=plt.cm.gray, alpha=0.3)\n",
    "    for i in range(conf_matrix.shape[0]):\n",
    "        for j in range(conf_matrix.shape[1]):\n",
    "            ax.text(x=j, y=i,s=conf_matrix[i, j].numpy(), va='center', ha='center', size='xx-large')\n",
    "    \n",
    "    plt.xlabel('Predictions', fontsize=18)\n",
    "    plt.ylabel('Actuals', fontsize=18)\n",
    "    plt.title(f'Confusion Matrix (weighted F1: {weighted_f1})', fontsize=18)\n",
    "\n",
    "    return plt\n",
    "\n",
    "def discard_histogram_for_model(model, discard_ds):\n",
    "    preds = model.predict(discard_ds, verbose=0)\n",
    "    max_arg = np.argmax(preds, axis=1)\n",
    "    max_value = np.amax(preds, axis=1)\n",
    "    bad_args = max_arg[max_value > .8]\n",
    "\n",
    "    high_prob_crap_percent = (np.count_nonzero(max_value > .8)/len(max_value))*100\n",
    "\n",
    "    ax = sns.histplot(\n",
    "        bad_args,\n",
    "    )\n",
    "    ax.set_title(\n",
    "        f\"High probability predictions on discard pile\\n({high_prob_crap_percent}%)\"\n",
    "    )\n",
    "    ax.set_xlim(0,len(label_map)-1)\n",
    "    ax.set_xticks(range(0,len(label_map)))\n",
    "    return ax"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fit Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if SELECTED_MODEL:\n",
    "    (train_ds, val_ds, test_ds) = load_train_data()\n",
    "    discard_ds = load_discard_images()\n",
    "    history = generate_model(SELECTED_MODEL, train_ds=train_ds, val_ds=val_ds)\n",
    "    history.model.save('./output')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if SELECTED_MODEL:\n",
    "    history.model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # if SELECTED_MODEL:\n",
    "# print(SELECTED_MODEL)\n",
    "# from keras.utils.vis_utils import plot_model\n",
    "# plot_model(history.model, show_shapes=True, show_layer_names=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if SELECTED_MODEL:\n",
    "    confusion_matrix_for_model(history.model, test_ds=test_ds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if SELECTED_MODEL:\n",
    "    discard_histogram_for_model(history.model, discard_ds=discard_ds)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TFLite Conversion\n",
    "This expects the TF model to be in `./output`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if SELECTED_MODEL:\n",
    "    def representative_data_gen():\n",
    "        (train_ds, _, _) = load_train_data()\n",
    "        for batch in train_ds:\n",
    "            yield [batch[0]]\n",
    "\n",
    "    # Convert the model\n",
    "    converter = tf.lite.TFLiteConverter.from_saved_model('./output')\n",
    "    converter.optimizations = [tf.lite.Optimize.DEFAULT]\n",
    "    converter.representative_dataset = representative_data_gen\n",
    "    converter.target_spec.supported_ops = [tf.lite.OpsSet.TFLITE_BUILTINS_INT8]\n",
    "    converter.inference_input_type = tf.uint8\n",
    "    converter.inference_output_type = tf.uint8\n",
    "    tflite_model = converter.convert()\n",
    "\n",
    "    # Save the model.\n",
    "    with open('model.tflite', 'wb') as f:\n",
    "        f.write(tflite_model)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluate TFLite model the same way"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TFLiteModelWrapper:\n",
    "    \"\"\"\n",
    "    Wrap a tflite model with something that provides a predict() method\n",
    "    that works like a normal model so we can use our existing test functions\n",
    "    against them\n",
    "    \"\"\"\n",
    "    def __init__(self, path):\n",
    "        self.interpreter = tf.lite.Interpreter(path)\n",
    "        self.input_details = self.interpreter.get_input_details()\n",
    "        self.output_details = self.interpreter.get_output_details()\n",
    "        self.interpreter.allocate_tensors()\n",
    "\n",
    "    def predict(self, data, verbose=0):\n",
    "        ret = []\n",
    "        if not hasattr(data, 'shape'):\n",
    "            # This is a batch dataset\n",
    "            batches = [b for b in data]\n",
    "        else:\n",
    "            batches = [data]\n",
    "        for batch in batches:\n",
    "            for image in batch:\n",
    "                expand_image = np.expand_dims(image, axis=0)\n",
    "                self.interpreter.set_tensor(self.input_details[0]['index'], expand_image.astype(np.uint8))\n",
    "                self.interpreter.invoke()\n",
    "                output_data = self.interpreter.get_tensor(self.output_details[0]['index'])\n",
    "                # Scale back to a float so the comparison functions based on the\n",
    "                # un-converted model will still work\n",
    "                ret.append(output_data/255)\n",
    "\n",
    "        return np.squeeze(np.array(ret))\n",
    "\n",
    "tfl = TFLiteModelWrapper('model.tflite')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if SELECTED_MODEL:\n",
    "    confusion_matrix_for_model(tfl, test_ds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if SELECTED_MODEL:\n",
    "    discard_histogram_for_model(tfl, discard_ds)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Write out model CPP"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "model_hpp = \"\"\"\n",
    "#ifndef _MODEL_H_\n",
    "#define _MODEL_H_\n",
    "\n",
    "extern const unsigned char model_tflite[];\n",
    "extern const unsigned int model_tflite_len;\n",
    "\n",
    "#endif // _MODEL_H_\n",
    "\"\"\"\n",
    "with open(\"esp32/wand/main/model.hpp\", \"w\") as f:\n",
    "    f.write(model_hpp)\n",
    "\n",
    "with open('model.tflite', 'rb') as f:\n",
    "    d = f.read()\n",
    "\n",
    "BYTES_PER_LINE=15\n",
    "cpp_out = '#include \"model.hpp\"\\n\\n'\n",
    "cpp_out += 'alignas(8) const unsigned char model_tflite[] = {\\n'\n",
    "(whole_lines, final_line_size) = divmod(len(d), BYTES_PER_LINE)\n",
    "for i in range(whole_lines):\n",
    "    if final_line_size == 0 and i == whole_lines - 1:\n",
    "        endchar = '\\n};'\n",
    "    else:\n",
    "        endchar=','\n",
    "    cpp_out += (' ' * 4) + ', '.join([f\"0x{b:02x}\" for b in d[i*BYTES_PER_LINE:(i*BYTES_PER_LINE)+BYTES_PER_LINE]]) + f'{endchar}\\n'\n",
    "if final_line_size > 0:\n",
    "    cpp_out += (' ' * 4) + ', '.join([f\"0x{b:02x}\" for b in d[whole_lines*BYTES_PER_LINE:]]) + '\\n};\\n'\n",
    "cpp_out += f\"const unsigned int model_tflite_len = {len(d)};\\n\"\n",
    "\n",
    "with open(\"esp32/wand/main/model.cpp\", \"w\") as f:\n",
    "    f.write(cpp_out)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
