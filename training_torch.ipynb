{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "TRAIN_PATH='images/train'\n",
    "TEST_PATH='images/test'\n",
    "LABELS_PATH='images/labels.yaml'\n",
    "ANNOTATIONS_PATH='images/annotations.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# files = os.listdir(TRAIN_PATH)\n",
    "# numfiles = len(files)\n",
    "# images = []\n",
    "# for imfile in files:\n",
    "#     if imfile.endswith('.yaml'):\n",
    "#         continue\n",
    "#     images.append(Image.open(os.path.join(TRAIN_PATH, imfile)))\n",
    "\n",
    "# _, axes = plt.subplots(nrows=int(numfiles/5), ncols=5, figsize=(20, 20))\n",
    "# for ax, image, filename in zip([i for row in axes for i in row], images, files):\n",
    "#     ax.set_axis_off()\n",
    "#     ax.imshow(image, cmap=plt.cm.gray_r, interpolation=\"nearest\")\n",
    "#     ax.set_title(f\"Training: {filename}\")\n",
    "\n",
    "# labels\n",
    "# locomotor\n",
    "# incendio\n",
    "# descendo\n",
    "# tarantallegra - w thing\n",
    "# arresto_momemtum - m thing\n",
    "# specialis - s thing\n",
    "# mimblewimble - sideways s thing\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x7f9e1e114790>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torchvision import datasets, transforms\n",
    "from torch.optim.lr_scheduler import StepLR\n",
    "\n",
    "torch.manual_seed(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# transform = transforms.Compose(\n",
    "#     [\n",
    "#         transforms.ToTensor(),\n",
    "#         # transforms.Normalize((0.1307,), (0.3081,)),\n",
    "#         transforms.Resize((100,100))\n",
    "#     ]\n",
    "# )\n",
    "\n",
    "import yaml\n",
    "\n",
    "with open(LABELS_PATH) as f:\n",
    "    label_map = yaml.load(f, Loader=yaml.SafeLoader)[\"labels\"]\n",
    "annotations = pd.read_csv(ANNOTATIONS_PATH)\n",
    "all_images = []\n",
    "imfiles = os.listdir(TRAIN_PATH)\n",
    "for imfile in imfiles:\n",
    "    if imfile.endswith(\".yaml\"):\n",
    "        continue\n",
    "    label = annotations[annotations.filename == os.path.join(TRAIN_PATH, imfile)]\n",
    "    if label.empty:\n",
    "        continue    \n",
    "    all_images.append(\n",
    "        [\n",
    "            np.reshape(\n",
    "                    np.array(\n",
    "                        Image.open(os.path.join(TRAIN_PATH, imfile)), dtype=np.float32\n",
    "                    ),\n",
    "                (1, 40, 40),\n",
    "            ),\n",
    "            label_map[label.label.item()],\n",
    "        ]\n",
    "    )\n",
    "\n",
    "splits = train_test_split(all_images)\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(splits[0], batch_size=10)\n",
    "test_loader = torch.utils.data.DataLoader(splits[1], batch_size=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# _, axes = plt.subplots(nrows=10, ncols=train_loader.batch_size, figsize=(20, 20))\n",
    "# for ax, image, filename in zip([i for row in axes for i in row], [i[0] for batch in train_loader for i in batch], [i[1] for batch in train_loader for i in batch]):\n",
    "#     ax.set_axis_off()\n",
    "#     ax.imshow(image.reshape(40,40), cmap=plt.cm.gray_r, interpolation=\"nearest\")\n",
    "#     ax.set_title(f\"Training: {filename}\")\n",
    "img = [i[0] for batch in train_loader for i in batch][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "i = Image.fromarray(img.numpy().reshape(40,40))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAACgAAAAoCAIAAAADnC86AAACLUlEQVR4nNWYO8rqQBiGX8QLeAnuwEptBTurbEArC4kbsLBRLNyAIIhWtpZeFmAv1iJYKbiAiHYaUDHC/MWcM4TEjJPbfzhvlcy88z2TuXyTBBAQ+avr9cqxzedz5mw2myKRRcGEkF6vJ2IjhFSrVU9UTdMIIe12m4VOp9N21EajAUCSJHrrCUxDFItFAP1+/2PESqViKqe3sVjMJXU0GhkjRqPRj+DhcEgIORwOJnAymXQJputltVqxkk6nY11l1t4oisIf7ZDTrmw2GwCSJDlt6BW8Xq93ux2A6XRKS2RZttpms5kncCQSAXC/342FqqoCUBSF3sbjcQD5fN7UVtd1AIlEgo/4LLt5ouWZTIZd53I5k8e6PnwD12o1dp1KpUyeUqlECDmfz/6DH48Hx8OvcglmucmY16zi1Dpe1VTP55NeuE4RLsGv10vERie+2+06i87PPqyWP4t2BpdP7FTWzRY4uNVqOW7zNdGLDLUsyx89Pjzx5XLh1NolEE/gxWIBYL/fczzGQ9o3sKDG4zGA7XYrCqYHnzUJOxXd9PQQE9LX1xf2PisYyjfw7XZzDfY0x+KzcDweAQwGA3/ATHanE9NkMnEQ7utQswTyFQzLaP9SrmYKh8M+gGkCEdRyuQSQzWb/9MAL2JHK5XKhUGCJ7FeHmr6Q/wOwUf8nWGQXuQHX63UAmqbZGU6nUyDgQMUDf/3iC1DGHzmh0Ideqqr6fr8DYeu6bvc96EU/7QLjIpu6O6cAAAAASUVORK5CYII=",
      "text/plain": [
       "<PIL.Image.Image image mode=RGB size=40x40>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "i.convert(\"RGB\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(1, 4, 3, 1)\n",
    "        # self.conv2 = nn.Conv2d(4, 8, 3, 1)\n",
    "        self.dropout1 = nn.Dropout(0.5)\n",
    "        self.dropout2 = nn.Dropout(0.5)\n",
    "        self.fc1 = nn.Linear(1444, 64)\n",
    "        self.fc2 = nn.Linear(64, 8)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv1(x)\n",
    "        x = F.relu(x)\n",
    "        # x = self.conv2(x)\n",
    "        # x = F.relu(x)\n",
    "        x = F.max_pool2d(x, 2)\n",
    "        x = self.dropout1(x)\n",
    "        x = torch.flatten(x, 1)\n",
    "        x = self.fc1(x)\n",
    "        x = F.relu(x)\n",
    "        x = self.dropout2(x)\n",
    "        x = self.fc2(x)\n",
    "        output = F.log_softmax(x, dim=1)\n",
    "        return output\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Net().to('cuda')\n",
    "optimizer = optim.Adadelta(model.parameters(), lr=.1)\n",
    "scheduler = StepLR(optimizer, step_size=1, gamma=0.7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, device, train_loader, optimizer, epoch):\n",
    "    model.train()\n",
    "    for batch_idx, (data, target) in enumerate(train_loader):\n",
    "        data, target = data.to(device), target.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        output = model(data)\n",
    "        loss = F.nll_loss(output, target)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        if batch_idx % 2 == 0:\n",
    "            print('Train Epoch: {} [{}/{} ({:.0f}%)]\\tLoss: {:.6f}'.format(\n",
    "                epoch, batch_idx * len(data), len(train_loader.dataset),\n",
    "                100. * batch_idx / len(train_loader), loss.item()))\n",
    "        del data\n",
    "        del target\n",
    "\n",
    "def test(model, device, test_loader):\n",
    "    model.eval()\n",
    "    test_loss = 0\n",
    "    correct = 0\n",
    "    with torch.no_grad():\n",
    "        for data, target in test_loader:\n",
    "            data, target = data.to(device), target.to(device)\n",
    "            output = model(data)\n",
    "            test_loss += F.nll_loss(output, target, reduction='sum').item()  # sum up batch loss\n",
    "            pred = output.argmax(dim=1, keepdim=True)  # get the index of the max log-probability\n",
    "            correct += pred.eq(target.view_as(pred)).sum().item()\n",
    "\n",
    "    test_loss /= len(test_loader.dataset)\n",
    "\n",
    "    print('\\nTest set: Average loss: {:.4f}, Accuracy: {}/{} ({:.0f}%)\\n'.format(\n",
    "        test_loss, correct, len(test_loader.dataset),\n",
    "        100. * correct / len(test_loader.dataset)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 1 [0/347 (0%)]\tLoss: 29.225262\n",
      "Train Epoch: 1 [20/347 (6%)]\tLoss: 20.730671\n",
      "Train Epoch: 1 [40/347 (11%)]\tLoss: 18.171814\n",
      "Train Epoch: 1 [60/347 (17%)]\tLoss: 7.365547\n",
      "Train Epoch: 1 [80/347 (23%)]\tLoss: 10.743946\n",
      "Train Epoch: 1 [100/347 (29%)]\tLoss: 14.372116\n",
      "Train Epoch: 1 [120/347 (34%)]\tLoss: 12.594039\n",
      "Train Epoch: 1 [140/347 (40%)]\tLoss: 12.242796\n",
      "Train Epoch: 1 [160/347 (46%)]\tLoss: 8.279393\n",
      "Train Epoch: 1 [180/347 (51%)]\tLoss: 18.288280\n",
      "Train Epoch: 1 [200/347 (57%)]\tLoss: 6.290343\n",
      "Train Epoch: 1 [220/347 (63%)]\tLoss: 6.261518\n",
      "Train Epoch: 1 [240/347 (69%)]\tLoss: 4.283874\n",
      "Train Epoch: 1 [260/347 (74%)]\tLoss: 3.593957\n",
      "Train Epoch: 1 [280/347 (80%)]\tLoss: 16.340118\n",
      "Train Epoch: 1 [300/347 (86%)]\tLoss: 1.070534\n",
      "Train Epoch: 1 [320/347 (91%)]\tLoss: 3.417746\n",
      "Train Epoch: 1 [238/347 (97%)]\tLoss: 3.044662\n",
      "\n",
      "Test set: Average loss: 0.9538, Accuracy: 103/116 (89%)\n",
      "\n",
      "Train Epoch: 2 [0/347 (0%)]\tLoss: 3.366131\n",
      "Train Epoch: 2 [20/347 (6%)]\tLoss: 3.076607\n",
      "Train Epoch: 2 [40/347 (11%)]\tLoss: 4.716659\n",
      "Train Epoch: 2 [60/347 (17%)]\tLoss: 5.540487\n",
      "Train Epoch: 2 [80/347 (23%)]\tLoss: 2.861844\n",
      "Train Epoch: 2 [100/347 (29%)]\tLoss: 2.724393\n",
      "Train Epoch: 2 [120/347 (34%)]\tLoss: 3.084535\n",
      "Train Epoch: 2 [140/347 (40%)]\tLoss: 1.037797\n",
      "Train Epoch: 2 [160/347 (46%)]\tLoss: 1.299871\n",
      "Train Epoch: 2 [180/347 (51%)]\tLoss: 6.566787\n",
      "Train Epoch: 2 [200/347 (57%)]\tLoss: 2.665897\n",
      "Train Epoch: 2 [220/347 (63%)]\tLoss: 0.545504\n",
      "Train Epoch: 2 [240/347 (69%)]\tLoss: 6.196294\n",
      "Train Epoch: 2 [260/347 (74%)]\tLoss: 1.459781\n",
      "Train Epoch: 2 [280/347 (80%)]\tLoss: 2.984187\n",
      "Train Epoch: 2 [300/347 (86%)]\tLoss: 0.386470\n",
      "Train Epoch: 2 [320/347 (91%)]\tLoss: 3.626739\n",
      "Train Epoch: 2 [238/347 (97%)]\tLoss: 5.074451\n",
      "\n",
      "Test set: Average loss: 0.6973, Accuracy: 109/116 (94%)\n",
      "\n",
      "Train Epoch: 3 [0/347 (0%)]\tLoss: 4.449382\n",
      "Train Epoch: 3 [20/347 (6%)]\tLoss: 4.382178\n",
      "Train Epoch: 3 [40/347 (11%)]\tLoss: 1.740838\n",
      "Train Epoch: 3 [60/347 (17%)]\tLoss: 0.918388\n",
      "Train Epoch: 3 [80/347 (23%)]\tLoss: 1.802122\n",
      "Train Epoch: 3 [100/347 (29%)]\tLoss: 0.223803\n",
      "Train Epoch: 3 [120/347 (34%)]\tLoss: 2.378403\n",
      "Train Epoch: 3 [140/347 (40%)]\tLoss: 0.049469\n",
      "Train Epoch: 3 [160/347 (46%)]\tLoss: 0.996563\n",
      "Train Epoch: 3 [180/347 (51%)]\tLoss: 4.851139\n",
      "Train Epoch: 3 [200/347 (57%)]\tLoss: 2.279612\n",
      "Train Epoch: 3 [220/347 (63%)]\tLoss: 1.323753\n",
      "Train Epoch: 3 [240/347 (69%)]\tLoss: 5.484220\n",
      "Train Epoch: 3 [260/347 (74%)]\tLoss: 1.134561\n",
      "Train Epoch: 3 [280/347 (80%)]\tLoss: 2.074419\n",
      "Train Epoch: 3 [300/347 (86%)]\tLoss: 0.627614\n",
      "Train Epoch: 3 [320/347 (91%)]\tLoss: 1.742764\n",
      "Train Epoch: 3 [238/347 (97%)]\tLoss: 6.257817\n",
      "\n",
      "Test set: Average loss: 0.6925, Accuracy: 110/116 (95%)\n",
      "\n",
      "Train Epoch: 4 [0/347 (0%)]\tLoss: 0.134246\n",
      "Train Epoch: 4 [20/347 (6%)]\tLoss: 1.329173\n",
      "Train Epoch: 4 [40/347 (11%)]\tLoss: 0.202370\n",
      "Train Epoch: 4 [60/347 (17%)]\tLoss: 4.766657\n",
      "Train Epoch: 4 [80/347 (23%)]\tLoss: 0.336083\n",
      "Train Epoch: 4 [100/347 (29%)]\tLoss: 0.024160\n",
      "Train Epoch: 4 [120/347 (34%)]\tLoss: 1.147121\n",
      "Train Epoch: 4 [140/347 (40%)]\tLoss: 0.056853\n",
      "Train Epoch: 4 [160/347 (46%)]\tLoss: 0.006477\n",
      "Train Epoch: 4 [180/347 (51%)]\tLoss: 3.078615\n",
      "Train Epoch: 4 [200/347 (57%)]\tLoss: 3.210995\n",
      "Train Epoch: 4 [220/347 (63%)]\tLoss: 4.681633\n",
      "Train Epoch: 4 [240/347 (69%)]\tLoss: 2.588166\n",
      "Train Epoch: 4 [260/347 (74%)]\tLoss: 0.214103\n",
      "Train Epoch: 4 [280/347 (80%)]\tLoss: 1.011678\n",
      "Train Epoch: 4 [300/347 (86%)]\tLoss: 0.040396\n",
      "Train Epoch: 4 [320/347 (91%)]\tLoss: 0.621635\n",
      "Train Epoch: 4 [238/347 (97%)]\tLoss: 1.437386\n",
      "\n",
      "Test set: Average loss: 0.6831, Accuracy: 110/116 (95%)\n",
      "\n",
      "Train Epoch: 5 [0/347 (0%)]\tLoss: 0.174947\n",
      "Train Epoch: 5 [20/347 (6%)]\tLoss: 3.593908\n",
      "Train Epoch: 5 [40/347 (11%)]\tLoss: 1.449045\n",
      "Train Epoch: 5 [60/347 (17%)]\tLoss: 2.899073\n",
      "Train Epoch: 5 [80/347 (23%)]\tLoss: 1.582767\n",
      "Train Epoch: 5 [100/347 (29%)]\tLoss: 0.054998\n",
      "Train Epoch: 5 [120/347 (34%)]\tLoss: 2.765457\n",
      "Train Epoch: 5 [140/347 (40%)]\tLoss: 0.095143\n",
      "Train Epoch: 5 [160/347 (46%)]\tLoss: 0.007176\n",
      "Train Epoch: 5 [180/347 (51%)]\tLoss: 3.787986\n",
      "Train Epoch: 5 [200/347 (57%)]\tLoss: 0.091652\n",
      "Train Epoch: 5 [220/347 (63%)]\tLoss: 0.630954\n",
      "Train Epoch: 5 [240/347 (69%)]\tLoss: 0.649508\n",
      "Train Epoch: 5 [260/347 (74%)]\tLoss: 1.315804\n",
      "Train Epoch: 5 [280/347 (80%)]\tLoss: 2.589108\n",
      "Train Epoch: 5 [300/347 (86%)]\tLoss: 1.553099\n",
      "Train Epoch: 5 [320/347 (91%)]\tLoss: 1.487369\n",
      "Train Epoch: 5 [238/347 (97%)]\tLoss: 2.320453\n",
      "\n",
      "Test set: Average loss: 0.6759, Accuracy: 111/116 (96%)\n",
      "\n",
      "Train Epoch: 6 [0/347 (0%)]\tLoss: 0.365570\n",
      "Train Epoch: 6 [20/347 (6%)]\tLoss: 4.627550\n",
      "Train Epoch: 6 [40/347 (11%)]\tLoss: 0.730672\n",
      "Train Epoch: 6 [60/347 (17%)]\tLoss: 2.107001\n",
      "Train Epoch: 6 [80/347 (23%)]\tLoss: 0.448510\n",
      "Train Epoch: 6 [100/347 (29%)]\tLoss: 0.867676\n",
      "Train Epoch: 6 [120/347 (34%)]\tLoss: 2.017606\n",
      "Train Epoch: 6 [140/347 (40%)]\tLoss: 0.520181\n",
      "Train Epoch: 6 [160/347 (46%)]\tLoss: 1.555652\n",
      "Train Epoch: 6 [180/347 (51%)]\tLoss: 1.604165\n",
      "Train Epoch: 6 [200/347 (57%)]\tLoss: 1.653711\n",
      "Train Epoch: 6 [220/347 (63%)]\tLoss: 2.880863\n",
      "Train Epoch: 6 [240/347 (69%)]\tLoss: 1.769940\n",
      "Train Epoch: 6 [260/347 (74%)]\tLoss: 1.508990\n",
      "Train Epoch: 6 [280/347 (80%)]\tLoss: 2.845786\n",
      "Train Epoch: 6 [300/347 (86%)]\tLoss: 2.379229\n",
      "Train Epoch: 6 [320/347 (91%)]\tLoss: 0.596994\n",
      "Train Epoch: 6 [238/347 (97%)]\tLoss: 4.470302\n",
      "\n",
      "Test set: Average loss: 0.6726, Accuracy: 111/116 (96%)\n",
      "\n",
      "Train Epoch: 7 [0/347 (0%)]\tLoss: 0.066836\n",
      "Train Epoch: 7 [20/347 (6%)]\tLoss: 3.195308\n",
      "Train Epoch: 7 [40/347 (11%)]\tLoss: 2.375112\n",
      "Train Epoch: 7 [60/347 (17%)]\tLoss: 0.771114\n",
      "Train Epoch: 7 [80/347 (23%)]\tLoss: 0.041806\n",
      "Train Epoch: 7 [100/347 (29%)]\tLoss: 0.097053\n",
      "Train Epoch: 7 [120/347 (34%)]\tLoss: 3.891043\n",
      "Train Epoch: 7 [140/347 (40%)]\tLoss: 0.631894\n",
      "Train Epoch: 7 [160/347 (46%)]\tLoss: 0.416994\n",
      "Train Epoch: 7 [180/347 (51%)]\tLoss: 2.508834\n",
      "Train Epoch: 7 [200/347 (57%)]\tLoss: 1.649377\n",
      "Train Epoch: 7 [220/347 (63%)]\tLoss: 0.503868\n",
      "Train Epoch: 7 [240/347 (69%)]\tLoss: 1.721017\n",
      "Train Epoch: 7 [260/347 (74%)]\tLoss: 0.169613\n",
      "Train Epoch: 7 [280/347 (80%)]\tLoss: 3.222766\n",
      "Train Epoch: 7 [300/347 (86%)]\tLoss: 1.820780\n",
      "Train Epoch: 7 [320/347 (91%)]\tLoss: 0.698139\n",
      "Train Epoch: 7 [238/347 (97%)]\tLoss: 2.907049\n",
      "\n",
      "Test set: Average loss: 0.6633, Accuracy: 111/116 (96%)\n",
      "\n",
      "Train Epoch: 8 [0/347 (0%)]\tLoss: 0.906156\n",
      "Train Epoch: 8 [20/347 (6%)]\tLoss: 3.708958\n",
      "Train Epoch: 8 [40/347 (11%)]\tLoss: 1.958818\n",
      "Train Epoch: 8 [60/347 (17%)]\tLoss: 0.364374\n",
      "Train Epoch: 8 [80/347 (23%)]\tLoss: 1.105560\n",
      "Train Epoch: 8 [100/347 (29%)]\tLoss: 0.077685\n",
      "Train Epoch: 8 [120/347 (34%)]\tLoss: 0.654196\n",
      "Train Epoch: 8 [140/347 (40%)]\tLoss: 0.411450\n",
      "Train Epoch: 8 [160/347 (46%)]\tLoss: 0.044671\n",
      "Train Epoch: 8 [180/347 (51%)]\tLoss: 2.783401\n",
      "Train Epoch: 8 [200/347 (57%)]\tLoss: 1.101139\n",
      "Train Epoch: 8 [220/347 (63%)]\tLoss: 1.225121\n",
      "Train Epoch: 8 [240/347 (69%)]\tLoss: 0.002594\n",
      "Train Epoch: 8 [260/347 (74%)]\tLoss: 1.328704\n",
      "Train Epoch: 8 [280/347 (80%)]\tLoss: 2.252608\n",
      "Train Epoch: 8 [300/347 (86%)]\tLoss: 0.137641\n",
      "Train Epoch: 8 [320/347 (91%)]\tLoss: 0.541539\n",
      "Train Epoch: 8 [238/347 (97%)]\tLoss: 1.374987\n",
      "\n",
      "Test set: Average loss: 0.6636, Accuracy: 111/116 (96%)\n",
      "\n",
      "Train Epoch: 9 [0/347 (0%)]\tLoss: 2.427821\n",
      "Train Epoch: 9 [20/347 (6%)]\tLoss: 1.178955\n",
      "Train Epoch: 9 [40/347 (11%)]\tLoss: 0.916363\n",
      "Train Epoch: 9 [60/347 (17%)]\tLoss: 0.895092\n",
      "Train Epoch: 9 [80/347 (23%)]\tLoss: 2.974351\n",
      "Train Epoch: 9 [100/347 (29%)]\tLoss: 0.147299\n",
      "Train Epoch: 9 [120/347 (34%)]\tLoss: 1.936883\n",
      "Train Epoch: 9 [140/347 (40%)]\tLoss: 2.546905\n",
      "Train Epoch: 9 [160/347 (46%)]\tLoss: 0.012789\n",
      "Train Epoch: 9 [180/347 (51%)]\tLoss: 3.300405\n",
      "Train Epoch: 9 [200/347 (57%)]\tLoss: 0.078034\n",
      "Train Epoch: 9 [220/347 (63%)]\tLoss: 3.093303\n",
      "Train Epoch: 9 [240/347 (69%)]\tLoss: 0.432907\n",
      "Train Epoch: 9 [260/347 (74%)]\tLoss: 1.543246\n",
      "Train Epoch: 9 [280/347 (80%)]\tLoss: 1.786072\n",
      "Train Epoch: 9 [300/347 (86%)]\tLoss: 1.121024\n",
      "Train Epoch: 9 [320/347 (91%)]\tLoss: 1.118376\n",
      "Train Epoch: 9 [238/347 (97%)]\tLoss: 2.299897\n",
      "\n",
      "Test set: Average loss: 0.6617, Accuracy: 111/116 (96%)\n",
      "\n",
      "Train Epoch: 10 [0/347 (0%)]\tLoss: 0.972794\n",
      "Train Epoch: 10 [20/347 (6%)]\tLoss: 0.022834\n",
      "Train Epoch: 10 [40/347 (11%)]\tLoss: 0.043707\n",
      "Train Epoch: 10 [60/347 (17%)]\tLoss: 1.986662\n",
      "Train Epoch: 10 [80/347 (23%)]\tLoss: 1.552745\n",
      "Train Epoch: 10 [100/347 (29%)]\tLoss: 0.001476\n",
      "Train Epoch: 10 [120/347 (34%)]\tLoss: 1.761286\n",
      "Train Epoch: 10 [140/347 (40%)]\tLoss: 1.122235\n",
      "Train Epoch: 10 [160/347 (46%)]\tLoss: 1.163530\n",
      "Train Epoch: 10 [180/347 (51%)]\tLoss: 0.983638\n",
      "Train Epoch: 10 [200/347 (57%)]\tLoss: 0.911838\n",
      "Train Epoch: 10 [220/347 (63%)]\tLoss: 0.301716\n",
      "Train Epoch: 10 [240/347 (69%)]\tLoss: 1.416537\n",
      "Train Epoch: 10 [260/347 (74%)]\tLoss: 0.694145\n",
      "Train Epoch: 10 [280/347 (80%)]\tLoss: 3.386911\n",
      "Train Epoch: 10 [300/347 (86%)]\tLoss: 0.105205\n",
      "Train Epoch: 10 [320/347 (91%)]\tLoss: 1.112347\n",
      "Train Epoch: 10 [238/347 (97%)]\tLoss: 3.711819\n",
      "\n",
      "Test set: Average loss: 0.6617, Accuracy: 111/116 (96%)\n",
      "\n",
      "Train Epoch: 11 [0/347 (0%)]\tLoss: 1.058903\n",
      "Train Epoch: 11 [20/347 (6%)]\tLoss: 1.705819\n",
      "Train Epoch: 11 [40/347 (11%)]\tLoss: 0.100419\n",
      "Train Epoch: 11 [60/347 (17%)]\tLoss: 1.854153\n",
      "Train Epoch: 11 [80/347 (23%)]\tLoss: 1.825213\n",
      "Train Epoch: 11 [100/347 (29%)]\tLoss: 1.255911\n",
      "Train Epoch: 11 [120/347 (34%)]\tLoss: 0.372052\n",
      "Train Epoch: 11 [140/347 (40%)]\tLoss: 0.258246\n",
      "Train Epoch: 11 [160/347 (46%)]\tLoss: 0.003141\n",
      "Train Epoch: 11 [180/347 (51%)]\tLoss: 0.712541\n",
      "Train Epoch: 11 [200/347 (57%)]\tLoss: 0.562843\n",
      "Train Epoch: 11 [220/347 (63%)]\tLoss: 0.423770\n",
      "Train Epoch: 11 [240/347 (69%)]\tLoss: 0.152887\n",
      "Train Epoch: 11 [260/347 (74%)]\tLoss: 1.260727\n",
      "Train Epoch: 11 [280/347 (80%)]\tLoss: 6.772639\n",
      "Train Epoch: 11 [300/347 (86%)]\tLoss: 0.002309\n",
      "Train Epoch: 11 [320/347 (91%)]\tLoss: 1.237103\n",
      "Train Epoch: 11 [238/347 (97%)]\tLoss: 3.808152\n",
      "\n",
      "Test set: Average loss: 0.6607, Accuracy: 111/116 (96%)\n",
      "\n",
      "Train Epoch: 12 [0/347 (0%)]\tLoss: 0.554021\n",
      "Train Epoch: 12 [20/347 (6%)]\tLoss: 2.871345\n",
      "Train Epoch: 12 [40/347 (11%)]\tLoss: 0.356311\n",
      "Train Epoch: 12 [60/347 (17%)]\tLoss: 0.037990\n",
      "Train Epoch: 12 [80/347 (23%)]\tLoss: 1.790469\n",
      "Train Epoch: 12 [100/347 (29%)]\tLoss: 0.018844\n",
      "Train Epoch: 12 [120/347 (34%)]\tLoss: 3.101741\n",
      "Train Epoch: 12 [140/347 (40%)]\tLoss: 0.012052\n",
      "Train Epoch: 12 [160/347 (46%)]\tLoss: 0.740129\n",
      "Train Epoch: 12 [180/347 (51%)]\tLoss: 4.393679\n",
      "Train Epoch: 12 [200/347 (57%)]\tLoss: 0.029919\n",
      "Train Epoch: 12 [220/347 (63%)]\tLoss: 0.463888\n",
      "Train Epoch: 12 [240/347 (69%)]\tLoss: 2.819478\n",
      "Train Epoch: 12 [260/347 (74%)]\tLoss: 0.001433\n",
      "Train Epoch: 12 [280/347 (80%)]\tLoss: 3.546067\n",
      "Train Epoch: 12 [300/347 (86%)]\tLoss: 1.149589\n",
      "Train Epoch: 12 [320/347 (91%)]\tLoss: 0.535877\n",
      "Train Epoch: 12 [238/347 (97%)]\tLoss: 5.038344\n",
      "\n",
      "Test set: Average loss: 0.6594, Accuracy: 111/116 (96%)\n",
      "\n",
      "Train Epoch: 13 [0/347 (0%)]\tLoss: 0.929723\n",
      "Train Epoch: 13 [20/347 (6%)]\tLoss: 2.726301\n",
      "Train Epoch: 13 [40/347 (11%)]\tLoss: 0.651734\n",
      "Train Epoch: 13 [60/347 (17%)]\tLoss: 0.945155\n",
      "Train Epoch: 13 [80/347 (23%)]\tLoss: 0.054855\n",
      "Train Epoch: 13 [100/347 (29%)]\tLoss: 0.163887\n",
      "Train Epoch: 13 [120/347 (34%)]\tLoss: 1.424980\n",
      "Train Epoch: 13 [140/347 (40%)]\tLoss: 3.205613\n",
      "Train Epoch: 13 [160/347 (46%)]\tLoss: 0.320208\n",
      "Train Epoch: 13 [180/347 (51%)]\tLoss: 1.980900\n",
      "Train Epoch: 13 [200/347 (57%)]\tLoss: 1.220493\n",
      "Train Epoch: 13 [220/347 (63%)]\tLoss: 0.217868\n",
      "Train Epoch: 13 [240/347 (69%)]\tLoss: 0.100161\n",
      "Train Epoch: 13 [260/347 (74%)]\tLoss: 1.084378\n",
      "Train Epoch: 13 [280/347 (80%)]\tLoss: 2.557113\n",
      "Train Epoch: 13 [300/347 (86%)]\tLoss: 1.026467\n",
      "Train Epoch: 13 [320/347 (91%)]\tLoss: 0.077410\n",
      "Train Epoch: 13 [238/347 (97%)]\tLoss: 3.777073\n",
      "\n",
      "Test set: Average loss: 0.6592, Accuracy: 111/116 (96%)\n",
      "\n",
      "Train Epoch: 14 [0/347 (0%)]\tLoss: 1.152297\n",
      "Train Epoch: 14 [20/347 (6%)]\tLoss: 2.069465\n",
      "Train Epoch: 14 [40/347 (11%)]\tLoss: 0.479106\n",
      "Train Epoch: 14 [60/347 (17%)]\tLoss: 1.877338\n",
      "Train Epoch: 14 [80/347 (23%)]\tLoss: 2.830746\n",
      "Train Epoch: 14 [100/347 (29%)]\tLoss: 0.559156\n",
      "Train Epoch: 14 [120/347 (34%)]\tLoss: 0.803976\n",
      "Train Epoch: 14 [140/347 (40%)]\tLoss: 1.017045\n",
      "Train Epoch: 14 [160/347 (46%)]\tLoss: 0.002944\n",
      "Train Epoch: 14 [180/347 (51%)]\tLoss: 0.593860\n",
      "Train Epoch: 14 [200/347 (57%)]\tLoss: 0.026776\n",
      "Train Epoch: 14 [220/347 (63%)]\tLoss: 1.059396\n",
      "Train Epoch: 14 [240/347 (69%)]\tLoss: 0.722607\n",
      "Train Epoch: 14 [260/347 (74%)]\tLoss: 0.889395\n",
      "Train Epoch: 14 [280/347 (80%)]\tLoss: 4.558551\n",
      "Train Epoch: 14 [300/347 (86%)]\tLoss: 0.011087\n",
      "Train Epoch: 14 [320/347 (91%)]\tLoss: 0.238024\n",
      "Train Epoch: 14 [238/347 (97%)]\tLoss: 2.145894\n",
      "\n",
      "Test set: Average loss: 0.6589, Accuracy: 111/116 (96%)\n",
      "\n",
      "Train Epoch: 15 [0/347 (0%)]\tLoss: 0.522236\n",
      "Train Epoch: 15 [20/347 (6%)]\tLoss: 3.820580\n",
      "Train Epoch: 15 [40/347 (11%)]\tLoss: 1.172849\n",
      "Train Epoch: 15 [60/347 (17%)]\tLoss: 0.690828\n",
      "Train Epoch: 15 [80/347 (23%)]\tLoss: 0.509279\n",
      "Train Epoch: 15 [100/347 (29%)]\tLoss: 0.153625\n",
      "Train Epoch: 15 [120/347 (34%)]\tLoss: 0.192304\n",
      "Train Epoch: 15 [140/347 (40%)]\tLoss: 0.624325\n",
      "Train Epoch: 15 [160/347 (46%)]\tLoss: 0.278672\n",
      "Train Epoch: 15 [180/347 (51%)]\tLoss: 2.889901\n",
      "Train Epoch: 15 [200/347 (57%)]\tLoss: 0.108657\n",
      "Train Epoch: 15 [220/347 (63%)]\tLoss: 0.008663\n",
      "Train Epoch: 15 [240/347 (69%)]\tLoss: 0.311850\n",
      "Train Epoch: 15 [260/347 (74%)]\tLoss: 0.538053\n",
      "Train Epoch: 15 [280/347 (80%)]\tLoss: 3.404558\n",
      "Train Epoch: 15 [300/347 (86%)]\tLoss: 0.000042\n",
      "Train Epoch: 15 [320/347 (91%)]\tLoss: 0.133748\n",
      "Train Epoch: 15 [238/347 (97%)]\tLoss: 1.638628\n",
      "\n",
      "Test set: Average loss: 0.6587, Accuracy: 111/116 (96%)\n",
      "\n",
      "Train Epoch: 16 [0/347 (0%)]\tLoss: 0.809913\n",
      "Train Epoch: 16 [20/347 (6%)]\tLoss: 1.674914\n",
      "Train Epoch: 16 [40/347 (11%)]\tLoss: 1.016671\n",
      "Train Epoch: 16 [60/347 (17%)]\tLoss: 0.080400\n",
      "Train Epoch: 16 [80/347 (23%)]\tLoss: 0.215868\n",
      "Train Epoch: 16 [100/347 (29%)]\tLoss: 0.007054\n",
      "Train Epoch: 16 [120/347 (34%)]\tLoss: 2.063927\n",
      "Train Epoch: 16 [140/347 (40%)]\tLoss: 0.409477\n",
      "Train Epoch: 16 [160/347 (46%)]\tLoss: 0.843790\n",
      "Train Epoch: 16 [180/347 (51%)]\tLoss: 0.127600\n",
      "Train Epoch: 16 [200/347 (57%)]\tLoss: 0.443155\n",
      "Train Epoch: 16 [220/347 (63%)]\tLoss: 0.342825\n",
      "Train Epoch: 16 [240/347 (69%)]\tLoss: 0.918307\n",
      "Train Epoch: 16 [260/347 (74%)]\tLoss: 1.494115\n",
      "Train Epoch: 16 [280/347 (80%)]\tLoss: 4.610990\n",
      "Train Epoch: 16 [300/347 (86%)]\tLoss: 1.617504\n",
      "Train Epoch: 16 [320/347 (91%)]\tLoss: 1.351765\n",
      "Train Epoch: 16 [238/347 (97%)]\tLoss: 0.460675\n",
      "\n",
      "Test set: Average loss: 0.6586, Accuracy: 111/116 (96%)\n",
      "\n",
      "Train Epoch: 17 [0/347 (0%)]\tLoss: 1.904174\n",
      "Train Epoch: 17 [20/347 (6%)]\tLoss: 2.041969\n",
      "Train Epoch: 17 [40/347 (11%)]\tLoss: 0.956650\n",
      "Train Epoch: 17 [60/347 (17%)]\tLoss: 0.326353\n",
      "Train Epoch: 17 [80/347 (23%)]\tLoss: 0.001441\n",
      "Train Epoch: 17 [100/347 (29%)]\tLoss: 1.062219\n",
      "Train Epoch: 17 [120/347 (34%)]\tLoss: 0.337719\n",
      "Train Epoch: 17 [140/347 (40%)]\tLoss: 0.486348\n",
      "Train Epoch: 17 [160/347 (46%)]\tLoss: 0.159148\n",
      "Train Epoch: 17 [180/347 (51%)]\tLoss: 1.664730\n",
      "Train Epoch: 17 [200/347 (57%)]\tLoss: 0.631051\n",
      "Train Epoch: 17 [220/347 (63%)]\tLoss: 1.948948\n",
      "Train Epoch: 17 [240/347 (69%)]\tLoss: 0.037300\n",
      "Train Epoch: 17 [260/347 (74%)]\tLoss: 0.495302\n",
      "Train Epoch: 17 [280/347 (80%)]\tLoss: 2.534453\n",
      "Train Epoch: 17 [300/347 (86%)]\tLoss: 0.020408\n",
      "Train Epoch: 17 [320/347 (91%)]\tLoss: 0.110259\n",
      "Train Epoch: 17 [238/347 (97%)]\tLoss: 1.233742\n",
      "\n",
      "Test set: Average loss: 0.6585, Accuracy: 111/116 (96%)\n",
      "\n",
      "Train Epoch: 18 [0/347 (0%)]\tLoss: 0.648584\n",
      "Train Epoch: 18 [20/347 (6%)]\tLoss: 3.023530\n",
      "Train Epoch: 18 [40/347 (11%)]\tLoss: 0.933894\n",
      "Train Epoch: 18 [60/347 (17%)]\tLoss: 0.044466\n",
      "Train Epoch: 18 [80/347 (23%)]\tLoss: 1.583738\n",
      "Train Epoch: 18 [100/347 (29%)]\tLoss: 0.993002\n",
      "Train Epoch: 18 [120/347 (34%)]\tLoss: 0.464791\n",
      "Train Epoch: 18 [140/347 (40%)]\tLoss: 1.788690\n",
      "Train Epoch: 18 [160/347 (46%)]\tLoss: 0.006023\n",
      "Train Epoch: 18 [180/347 (51%)]\tLoss: 3.086793\n",
      "Train Epoch: 18 [200/347 (57%)]\tLoss: 0.001845\n",
      "Train Epoch: 18 [220/347 (63%)]\tLoss: 0.403294\n",
      "Train Epoch: 18 [240/347 (69%)]\tLoss: 0.169126\n",
      "Train Epoch: 18 [260/347 (74%)]\tLoss: 0.471326\n",
      "Train Epoch: 18 [280/347 (80%)]\tLoss: 5.321614\n",
      "Train Epoch: 18 [300/347 (86%)]\tLoss: 0.098137\n",
      "Train Epoch: 18 [320/347 (91%)]\tLoss: 0.138300\n",
      "Train Epoch: 18 [238/347 (97%)]\tLoss: 4.684840\n",
      "\n",
      "Test set: Average loss: 0.6583, Accuracy: 111/116 (96%)\n",
      "\n",
      "Train Epoch: 19 [0/347 (0%)]\tLoss: 1.917312\n",
      "Train Epoch: 19 [20/347 (6%)]\tLoss: 3.873164\n",
      "Train Epoch: 19 [40/347 (11%)]\tLoss: 1.351211\n",
      "Train Epoch: 19 [60/347 (17%)]\tLoss: 0.610943\n",
      "Train Epoch: 19 [80/347 (23%)]\tLoss: 0.007769\n",
      "Train Epoch: 19 [100/347 (29%)]\tLoss: 0.562124\n",
      "Train Epoch: 19 [120/347 (34%)]\tLoss: 1.144408\n",
      "Train Epoch: 19 [140/347 (40%)]\tLoss: 0.109725\n",
      "Train Epoch: 19 [160/347 (46%)]\tLoss: 1.220595\n",
      "Train Epoch: 19 [180/347 (51%)]\tLoss: 2.901190\n",
      "Train Epoch: 19 [200/347 (57%)]\tLoss: 0.225229\n",
      "Train Epoch: 19 [220/347 (63%)]\tLoss: 0.291259\n",
      "Train Epoch: 19 [240/347 (69%)]\tLoss: 1.259250\n",
      "Train Epoch: 19 [260/347 (74%)]\tLoss: 0.013532\n",
      "Train Epoch: 19 [280/347 (80%)]\tLoss: 4.059805\n",
      "Train Epoch: 19 [300/347 (86%)]\tLoss: 0.001466\n",
      "Train Epoch: 19 [320/347 (91%)]\tLoss: 0.001504\n",
      "Train Epoch: 19 [238/347 (97%)]\tLoss: 0.318122\n",
      "\n",
      "Test set: Average loss: 0.6582, Accuracy: 111/116 (96%)\n",
      "\n",
      "Train Epoch: 20 [0/347 (0%)]\tLoss: 2.365481\n",
      "Train Epoch: 20 [20/347 (6%)]\tLoss: 1.344574\n",
      "Train Epoch: 20 [40/347 (11%)]\tLoss: 0.005631\n",
      "Train Epoch: 20 [60/347 (17%)]\tLoss: 1.319966\n",
      "Train Epoch: 20 [80/347 (23%)]\tLoss: 1.247807\n",
      "Train Epoch: 20 [100/347 (29%)]\tLoss: 0.004774\n",
      "Train Epoch: 20 [120/347 (34%)]\tLoss: 0.012272\n",
      "Train Epoch: 20 [140/347 (40%)]\tLoss: 0.519591\n",
      "Train Epoch: 20 [160/347 (46%)]\tLoss: 0.735413\n",
      "Train Epoch: 20 [180/347 (51%)]\tLoss: 0.399926\n",
      "Train Epoch: 20 [200/347 (57%)]\tLoss: 1.601517\n",
      "Train Epoch: 20 [220/347 (63%)]\tLoss: 0.584451\n",
      "Train Epoch: 20 [240/347 (69%)]\tLoss: 0.820387\n",
      "Train Epoch: 20 [260/347 (74%)]\tLoss: 0.002116\n",
      "Train Epoch: 20 [280/347 (80%)]\tLoss: 2.195550\n",
      "Train Epoch: 20 [300/347 (86%)]\tLoss: 1.629432\n",
      "Train Epoch: 20 [320/347 (91%)]\tLoss: 0.475498\n",
      "Train Epoch: 20 [238/347 (97%)]\tLoss: 2.170037\n",
      "\n",
      "Test set: Average loss: 0.6582, Accuracy: 111/116 (96%)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(1, 20 + 1):\n",
    "    train(model, 'cuda', train_loader, optimizer, epoch)\n",
    "    test(model, 'cuda', test_loader)\n",
    "    scheduler.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model.state_dict(), \"wand_cnn.pt\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "949777d72b0d2535278d3dc13498b2535136f6dfe0678499012e853ee9abcab1"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
