{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "import yaml\n",
    "import seaborn as sns\n",
    "from sklearn.manifold import TSNE\n",
    "\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import backend as K\n",
    "from tensorboard.plugins import projector\n",
    "from PIL import Image\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "LABELS_PATH = \"/workspaces/motion/labels.yaml\"\n",
    "MODEL_PATH = \"./output\"\n",
    "\n",
    "sns.set_style(\"darkgrid\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = tf.keras.models.load_model(MODEL_PATH)\n",
    "# model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(LABELS_PATH) as f:\n",
    "    label_map = yaml.load(f, Loader=yaml.SafeLoader)[\"labels\"]\n",
    "reverse_label_map = {v: k for k, v in label_map.items()}\n",
    "print(reverse_label_map)\n",
    "\n",
    "if 'discard' in label_map:\n",
    "    HAS_DISCARD = True\n",
    "else:\n",
    "    HAS_DISCARD = False\n",
    "\n",
    "if not HAS_DISCARD:\n",
    "    # If no explicit discard label we need to make one so Phoenix has\n",
    "    # the label to reference\n",
    "    discard_id = max(reverse_label_map.keys())+1\n",
    "    label_map['discard'] = discard_id\n",
    "    reverse_label_map[discard_id] = 'discard'\n",
    "\n",
    "image_files = []\n",
    "GOOD_IMAGES_DIR = \"/workspaces/motion/images/esp32/good\"\n",
    "for dir, _, files in os.walk(GOOD_IMAGES_DIR):\n",
    "    for file in files:\n",
    "        image_files.append((os.path.basename(dir), os.path.join(dir, file)))\n",
    "\n",
    "DISCARD_IMAGES_DIR = \"/workspaces/motion/images/esp32/discard/\"\n",
    "for dir, _, files in os.walk(DISCARD_IMAGES_DIR):\n",
    "    for file in files:\n",
    "        image_files.append(('discard', os.path.join(dir, file)))\n",
    "\n",
    "print(len(image_files))\n",
    "print(image_files[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "in_layer = model.get_layer('conv2d').input\n",
    "out_layer = model.get_layer('dense_1').output\n",
    "func = K.function([in_layer], [out_layer])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predicts = []\n",
    "img_arrays = []\n",
    "for img_desc in image_files:\n",
    "    img = Image.open(img_desc[1])\n",
    "    img_array = np.asarray(img, dtype=np.uint8).reshape(29, 40, 1)\n",
    "    formatted_img_array = np.expand_dims(img_array, axis=0)\n",
    "    img_arrays.append(formatted_img_array)\n",
    "\n",
    "img_arrays = np.squeeze(np.array(img_arrays), axis=1)\n",
    "vectors = func(img_arrays)[0]\n",
    "p = model.predict(img_arrays, verbose=False)\n",
    "pred_scores = np.amax(p, axis=1)\n",
    "pred_argmax = np.argmax(p, axis=1)\n",
    "for i in range(len(pred_scores)):\n",
    "    if HAS_DISCARD == False and pred_scores[i] < .98:\n",
    "        # If we aren't using explicit discard labels then fabricate one\n",
    "        # from lower-probability scores which we would throw out at runtime\n",
    "        predicts.append(('discard', pred_scores[i]))\n",
    "    else:\n",
    "        predicts.append((reverse_label_map[pred_argmax[i]], pred_scores[i]))\n",
    "\n",
    "vectors.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "\n",
    "pca = PCA(n_components=3)\n",
    "pca_result = pca.fit_transform(vectors)\n",
    "# y = [label_map[p.split('/')[3]] for p in image_files]\n",
    "y = [img_desc[0] for img_desc in image_files]\n",
    "y_int = [label_map[img_desc[0]] for img_desc in image_files]\n",
    "pca_df = pd.DataFrame(\n",
    "    {\n",
    "        \"pca-one\": pca_result[:, 0],\n",
    "        \"pca-two\": pca_result[:, 1],\n",
    "        \"pca-three\": pca_result[:, 2],\n",
    "        \"y\": y,\n",
    "        \"y-int\": y_int,\n",
    "    }\n",
    ")\n",
    "print(\n",
    "    \"Explained variation per principal component: {}, total explained variance: {}\".format(\n",
    "        pca.explained_variance_ratio_, sum(pca.explained_variance_ratio_)\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ax = sns.scatterplot(\n",
    "    x=pca_df[\"pca-one\"], y=pca_df[\"pca-two\"], hue=pca_df.y, alpha=0.4, legend=\"full\"\n",
    ")\n",
    "sns.move_legend(ax, \"upper left\", bbox_to_anchor=(1, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ax = plt.figure(figsize=(16, 10)).add_subplot(projection=\"3d\")\n",
    "scatter = ax.scatter(\n",
    "    xs=pca_df[\"pca-one\"],\n",
    "    ys=pca_df[\"pca-two\"],\n",
    "    zs=pca_df[\"pca-three\"],\n",
    "    c=pca_df[\"y-int\"],\n",
    "    cmap=\"tab10\",\n",
    "    label=pca_df[\"y-int\"],\n",
    ")\n",
    "ax.set_xlabel(\"pca-one\")\n",
    "ax.set_ylabel(\"pca-two\")\n",
    "ax.set_zlabel(\"pca-three\")\n",
    "legend1 = ax.legend(\n",
    "    scatter.legend_elements()[0],\n",
    "    # Not sure if the legend elements are guaranteed w.r.t. their order so better\n",
    "    # just parse the math expression\n",
    "    [\n",
    "        reverse_label_map[int(re.sub(r\"\\$\\\\mathdefault{(\\d+)}\\$\", r\"\\1\", i))]\n",
    "        for i in scatter.legend_elements()[1]\n",
    "    ],\n",
    "    loc=\"upper right\",\n",
    "    title=\"Pattern\",\n",
    ")\n",
    "ax.add_artist(legend1)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "tsne = TSNE(n_components=3, verbose=1, perplexity=40, n_iter=300)\n",
    "tsne_results = tsne.fit_transform(vectors)\n",
    "\n",
    "tsne_df = pd.DataFrame(\n",
    "    {\n",
    "        \"tsne-one\": tsne_results[:, 0],\n",
    "        \"tsne-two\": tsne_results[:, 1],\n",
    "        \"tsne-three\": tsne_results[:, 2],\n",
    "        \"y\": y,\n",
    "        \"y-int\": y_int,\n",
    "    }\n",
    ")\n"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "ax = plt.figure(figsize=(16, 10)).add_subplot(projection=\"3d\")\n",
    "scatter = ax.scatter(\n",
    "    xs=tsne_df[\"tsne-one\"],\n",
    "    ys=tsne_df[\"tsne-two\"],\n",
    "    zs=tsne_df[\"tsne-three\"],\n",
    "    c=tsne_df[\"y-int\"],\n",
    "    cmap=\"tab10\",\n",
    "    label=tsne_df[\"y-int\"],\n",
    ")\n",
    "ax.set_xlabel(\"tsne-one\")\n",
    "ax.set_ylabel(\"tsne-two\")\n",
    "ax.set_zlabel(\"tsne-three\")\n",
    "legend1 = ax.legend(\n",
    "    scatter.legend_elements()[0],\n",
    "    # Not sure if the legend elements are guaranteed w.r.t. their order so better\n",
    "    # just parse the math expression\n",
    "    [\n",
    "        reverse_label_map[int(re.sub(r\"\\$\\\\mathdefault{(\\d+)}\\$\", r\"\\1\", i))]\n",
    "        for i in scatter.legend_elements()[1]\n",
    "    ],\n",
    "    loc=\"upper right\",\n",
    "    title=\"Pattern\",\n",
    ")\n",
    "ax.add_artist(legend1)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "log_dir = '/workspaces/motion/logs'\n",
    "\n",
    "os.makedirs(os.path.join(log_dir, 'embeddings'), exist_ok=True)\n",
    "\n",
    "images_pil = []\n",
    "labels = []\n",
    "for img_desc in image_files:\n",
    "    img = Image.open(img_desc[1])\n",
    "    labels.append(img_desc[0])\n",
    "    images_pil.append(img)\n",
    "\n",
    "one_square_size = int(np.ceil(np.sqrt(len(vectors))))\n",
    "master_width = 40 * one_square_size\n",
    "master_height = 29 * one_square_size\n",
    "spriteimage = Image.new(\n",
    "    mode='RGBA',\n",
    "    size=(master_width, master_height),\n",
    "    color=(0,0,0,0) # fully transparent\n",
    ")\n",
    "for count, image in enumerate(images_pil):\n",
    "    div, mod = divmod(count, one_square_size)\n",
    "    h_loc = 29 * div\n",
    "    w_loc = 40 * mod\n",
    "    spriteimage.paste(image, (w_loc, h_loc))\n",
    "spriteimage.convert(\"RGB\").save(os.path.join(log_dir, 'embeddings/sprite.jpg'), transparency=0)\n",
    "\n",
    "with open(os.path.join(log_dir, 'embeddings/metadata.tsv'), 'w') as file: \n",
    "    file.write('shape\\ttest\\n')\n",
    "    for label in labels:\n",
    "        file.write(f'{label}\\tfoo\\n')\n",
    "\n",
    "weights = tf.Variable(model.get_layer('dense').get_weights()[0][1:])\n",
    "checkpoint = tf.train.Checkpoint(embedding=tf.Variable(vectors))\n",
    "checkpoint.save(os.path.join(log_dir, 'embedding.ckpt'))\n",
    "\n",
    "config = projector.ProjectorConfig()\n",
    "embedding = config.embeddings.add()\n",
    "embedding.tensor_name = \"embedding/.ATTRIBUTES/VARIABLE_VALUE\"\n",
    "embedding.metadata_path = 'embeddings/metadata.tsv'\n",
    "# embedding.sprite.image_path = 'embeddings/sprite.jpg'\n",
    "# embedding.sprite.single_image_dim.extend([40,29])\n",
    "projector.visualize_embeddings(log_dir, config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import phoenix as px\n",
    "\n",
    "px_df = pd.DataFrame({\n",
    "    'image_vector': [list(x) for x in vectors],\n",
    "    'actual': [i[0] for i in image_files],\n",
    "    'predict': [i[0] for i in predicts],\n",
    "    'predict_score': [i[1] for i in predicts],\n",
    "    'image_url': [f\"http://localhost:8000/{i[1][len('/workspaces/motion'):]}\" for i in image_files]\n",
    "})\n",
    "\n",
    "train_schema = px.Schema(\n",
    "    actual_label_column_name=\"actual\",\n",
    "    prediction_label_column_name=\"predict\",\n",
    "    prediction_score_column_name=\"predict_score\",\n",
    "    embedding_feature_column_names={\n",
    "        \"image_embedding\": px.EmbeddingColumnNames(\n",
    "            vector_column_name=\"image_vector\",\n",
    "            link_to_data_column_name=\"image_url\"\n",
    "        ),\n",
    "    },\n",
    ")\n",
    "\n",
    "px_ds = px.Dataset(px_df, train_schema)\n",
    "px.launch_app(px_ds)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
